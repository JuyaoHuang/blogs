---
title: 机器学习框架流程
author: JuyaoHuang
published: 2025-10-18
description: "机器学习的架构流程描述"
first_level_category: "AI"
second_level_category: "机器学习"
tags: ['机器学习']
draft: falsed
---

# 机器学习的框架流程

首先明确一点：**机器学习是后世所有AI应用的基础**，深度学习、大模型、LLM、vLLM、agent都是在机器学习基础上建立起来的。因此机器学习的经典内容和实现路线是需要特别熟悉的，尤其是在 **评价标准、数据清洗、特征工程、模型选择、模型训练和评估**方面。

本篇主要介绍机器学习的工作流程，在介绍完基本的工作流后，会对其中的一些重点地方做额外讲解。

本篇主要面向的是初入机器学习的工程师，因为不论是算法工程师的应用方向，还是研究算法底层实现的AI算法研究员，都应该掌握基本的机器学习基础 （更多倾向于AI算法研究员），在这之后学习主流的环境框架：PyTorch或TensorFlow，但本篇不做涉及。

## 机器学习的目的

开始之前，应该明确一下机器学习提出的目的。
**机器学习的最终目标都是为了从数据中自动学习出一个能够进行预测的数学函数 $f$** 
**重点**：
1. 自动学习  ----能够自行学习的模型
2. 预测      ----能够完成对未知的可信预测

这个函数 $f$ 接收一些输入（特征值 $X$），然后给出一个输出（预测 $\hat{y} $），这个输出 $hat{y}$ 应该尽可能地接近真实值 $y$。
$$
y \approx \hat{y} = f(X)
$$
例如，糖尿病预测中：

- X = {怀孕次数，BMI，胰岛素水平，年龄...}
- $y$ = {1（患病），0（不患病）}
- 目的：找到一个函数 $f$，把一个人的生理指标 X 输入进去，能够得到一个接近 1或者 0的预测结果 $\hat{y}$

## 实现架构
### 1. 定义问题
在训练获得此模型函数之前，应该**明确我们要做的事**：我们获得这个函数后要做的事情是什么，它要解决的问题是什么。明确了要解决的问题，才知道要选择什么算法模型做训练。

- **明确业务问题**：
     明确要解决的是什么问题。例如，是想预测房价，还是提高用户点击率
- **定义任务类型**：
    一般任务类型分为三类：
    - 分类问题： 预测类别，例如 "是否患病"
    - 回归问题： 预测数值，例如 "房价"
    - 聚类问题： 无监督分组
- **确定评估指标**：
    如何衡量模型是否训练成功。是追求高准确率，还是追求精确率/召回率
    - 准确率 Accuracy：判断某个类别的事物是不是属于目标类别，例如 苹果是不是水果
    - 精确率 Precision：判断某个事物是不是自己需要的那一类，例如 苹果是好的还是坏的。
- **可行性分析**：

- **价值分析**：
    分析此业务问题是否具有为了解决它而训练一个模型的价值，或者说，此业务是否能够被解决，如果无法解决，那它就没有实现的价值

### 2. 数据采集和EDA

在确定好问题之后，就要准备训练模型的数据集，并且对数据集进行清洗和分析。
*分析可选，因为这个数据分析太有门道和难度了，甚至有相关的工作岗位：数据分析工程师*
- 数据采集：
    获取所有可能相关的原始数据。数据可以来自公司数据库、公开数据集、爬虫、传感器等。数据的质量和数量直接决定了项目的上限
- **数据清洗**：
    真实世界的数据是很 "脏"的，没有那么完美的数据集给你使用。你需要在这一步解决**原始数据的缺失值、异常值、重复值**等问题，避免模型学习到了垃圾数据。
- 探索性数据分析（EDA）：
    通过可视化和统计的方式来理解数据，目的是为了发现数据中的规律、相关性，为后续特征工程提供灵感和依据。
    *"灵感"就意味着很难找*
    常见的可视化方式有：
    - 直方图
    - 散点图
    - 热力图

### 3. 特征工程

因为数学模型（算法）通常只理解数值，而原始信息一般是文本信息，或者部分数值（如时间，尺度差异大的特征）也不适合直接送入模型，因此要对数据进行转换，将其变为模型可理解的数据。

例如，将日期拆分为年、月、日，或者对文本进行向量化。

常用的操作为：
- 数据标准化/归一化：解决不同特征尺度不一的问题
- 独热编码：One-Hot Encoding，处理类别特征
- 特征选择：剔除无关或冗余的特征

一个好的特征工程可以直接让简单的模型性能翻倍

### 4. 数据划分

在训练模型之前，一般会在做好数据预处理后，对数据进行划分。将其划分为**训练集、测试集和验证集**，分别用来训练、测试、最终评估模型的效果，以防止[过拟合问题](#过拟合)。

### 5. 模型选择

处理好数据集后，就要选择合适的算法模型做训练。

**选择标准**：
- 问题类型：分类还是回归
- 数据特点：线性/非线性、数据量大/小
- 业务需求：高精度还是高速度，质量拉高还是速度为先

例如：
- 数据量不大，问题是二分类，逻辑回归模型就很好
- 数据量很大，特征类型间关系复杂，可能会上神经网络

这一步决定了要使用什么算法模型构建最终的预测函数 $f$

### 6. 模型训练（核心）

选取好模型后，我们就来到了激动人心的炼丹环节。

这一环节涉及到很多技术，国内高校大部分和机器学习有关的课程教的就是这部分内容的原理，例如逻辑回归、线性回归、梯度下降法、损失函数等等。
因此这部分我们也分三个部分解释，并且在后文会给出相关的知识介绍，但受篇幅限制，不会特别详细。

- 算法模型（Algorithm）：

    算法模型提供了一个具体的数学结构/框架，或者成为函数模板，它就是要炼丹的对象，可称为基底模型。

    以逻辑回归为例， 逻辑回归的模板是
    $$
    \hat{y} = \sigma(w^T X + b) \iff \hat{y} = \frac{1}{1 + e^{-(w^T X + b)}}
    $$
    这个模板定义了模型能学到的规律的形式，未来预测也是按照此公式去输出值。模型的任务就是在此模板下，找到**最好**的参数 $w$ 和 $b$
- 损失函数（Loss function）

    损失函数用来**衡量预测误差**
    对每一个训练样本，损失函数会计算出模型预测值 $\hat{y}$ 和真实值 $y$ 之间的差距。它的目的是**提供一个明确的、可量化的优化目标**：这个差距（损失）越小，模型就越好
- 优化器（Optimizer）

    优化器是**驱动模型参数更新的工具**
    它根据损失函数计算得到的误差，找到一个能让这个误差缩小的方向，然后告诉模型进行参数（例如逻辑回归的 $w$ 和 $b$）的微调
    最常用的就是梯度下降法（尤其是Adam算法）

**总结**：模型训练的过程就是：**优化器**不断调整**算法**的内部参数，它调整的唯一依据是如何让**损失函数**的值变得越来愈小。
### 7. 模型评估与参数回调

**目的**：
    检验模型的**泛化能力**。大白话就是，让模型面对新的数据，看看它的输出结果是否理想，误差是否达到预期值

**操作**：
    使用从未参与过训练的测试集/验证集评估模型的性能，根据预先选定的评价指标和目测效果，评价模型的优劣，是否需要继续迭代。
    常见的指标：
    1. 准确率 Accuracy
    2. 精确率 Precision
    3. 召回率 Recall
    4. 还有 TN、TP、FP、FN等
    评价指标介绍[看此处](#评价指标)
    如果模型效果不理想，那么需要回来调整第六步模型训练里的[超参数](#超参数)，例如梯度下降法的学习率、神经网络的隐藏层层数

    如果仍旧不理想，就要考虑第三步、第四步（换模型）了。
### 8. 模型部署与监控

训练好模型后，最后一步就是部署上线，应用到实际的业务中，不然就纯纯是空中楼阁。一个不能解决实际问题的算法，毫无价值

1. 部署：将模型集成到后端中，供给前端调用
2. 监控：
   持续监控模型在真实世界中的表现。因为世界是变化的，过去的数据规律可能在未来失效（称为“模型漂移”）。监控的目的是及时发现模型性能衰退，以便进行重新训练或更新。

## 完整示例：构建垃圾邮件过滤器

### 需求分析

用户收到垃圾邮件骚扰，需要一个自动过滤器，滤掉垃圾邮件。

### 1.问题定义

- **明确业务问题**：

    构建一个过滤器，过滤垃圾邮件
- **机器学习问题**：
- 
    找到一个函数 $f$，输入一封电子邮件的内容（$X$），输出一个预测值 $\hat{y}$，判断这封邮件是垃圾邮件（Spam）还是正常邮件（Ham）
    分析可知，这是一个**二分类问题**，令 "垃圾邮件"编码为 1，"正常邮件" 编码为 0.
- **确定评价指标**：

    我们自然希望准确率 Accuracy最高，但是**更不希望一封重要的正常邮件被错判为垃圾邮件**。即，在预测为"垃圾邮件"的结果中，我们希望它是真正的垃圾邮件的比例能够达到最高。因此，相比于准确率，精确率（该封邮件是否是垃圾邮件）指标更加关键和重要

### 2.数据采集和EDA

1. 获取数据集：
   从网上下载一个公开的邮件数据集，里面有成千上万封邮件，并且都标注好了是 Spam 还是 Ham。
2. 清洗数据：
   检查数据是否有缺失、损坏或重复的条目。
   - 如果是少量的单个邮件的某条数据缺失，可直接删除此封邮件，或者使用一些值如 ' '来代替内容。
3. EDA：
   - 统计 Spam 和 Ham 的邮件各有多少封，看看数据是否平衡。如果不平衡，可采用两种方法：
        1. 数据量足够大时，可删除数量较多的一方的数据，直到两方平衡
        2. 更常见的做法是：先用数量较少的一类数据集（假设是 Spam）进行训练，生成新的Spam，直到 Spam 的数量和 Ham相差不多
   - 制作 "词云"：
    查看 Spam邮件中最常出现的词（例如 "free", "viagra", "offer", "winner"），和 Ham中最常出现的词（如 "meeting", "report", "hello", "team"）。这能给我们一个直观的感受，认为二者的确有较为明显的差别，并且能够获得训练的数据

### 3.特征工程

由于算法模型，例如逻辑回归并不知道 "free viagra"这样的文本内容，只认识数字。
因此需要对文本内容采用向量化形式，将其转换（编码）为数学语言

**文本向量化**里常用的方法是 **词袋模型（Bag-of-Words）**：
1. 建立词汇表
   统计数据集中所有出现过的独立单词，形成一个巨大的词典（比如有5000个单词）
2. 向量化：
   对于每一封邮件，都创建一个长度为 5000 的向量。向量的每一个位置对应词典中的一个单词。如果词典中第 100 个单词是 "free"，而某封邮件里 "free" 出现了 2 次，那么这个向量在第100个位置的值就是 2。其他没出现的单词位置就是 0
   如此，通过词袋模型，就成功将每一封文本邮件，转换成了算法可处理的数字向量 $X$

### 4.模型选择

这是一个经典的二分类问题，并且特征（词向量）维度很高

逻辑回归算法就很不错，快速、简单。
因此选择的函数模板就是
$$
\hat{y} = \sigma(w^T X + b) \iff \hat{y} = \frac{1}{1 + e^{-(w^T X + b)}}
$$

### 5.模型训练

**前提**：已经划分好了训练集，拥有处理好的邮件向量 $X_train$ 和对应的标签 $y_train$ （0 或 1），即前文定义的 Spam是 1，Ham是 0

1. 初始化
    模型初始时是 无知 的。它内部的参数，即每个单词的权重 $w$，都是一个随机值
    
2. 前向传播 Prediction
   1. 从训练集获取一封邮件的向量 $X$
   2. 模型根据当前的权重 $w$，计算一个综合得分 score $z = wX+b$
   3. 使用 Sigmoid函数 $\sigma$ 将得分 $z$ 转换为一个概率 $\hat(y)$。例如，模型输出 $\hat{y}=0,4$，意思是 "模型认为这封邮件有40%的可能是垃圾邮件"
   
3. 计算损失函数 Loss function
    1. 现在，我们查看这封邮件的真实标签，发现它其实是垃圾邮件，即 $y = 1$
    
    2. 模型预测值 $\hat{y} = 0.4$，为了计算/量化真实值与预测值的误差，因此使用**损失函数**来量化该指标
    
    3. 分类问题常用的损失指标是 **交叉熵损失 Cross-Entropy Loss**
       1. 如果真实是1，预测值0.4，会有一个损失值。
       2. 如果真实是1，预测值0.1，损失值会急剧增大
       3. 如果真实是1，预测值0.9，损失值会非常小
       
       可以理解为，损失值是用来量化**误差**的指标，损失函数是用来计算损失值得
    4. 通过计算，我们得到了一个具体的损失值，比如 $Loss = 0.91 $。这个数字代表了模型在这一个样本上的表现有多差。
    
4. 反向传播和优化 Optimization
   
5. 迭代 Epoch

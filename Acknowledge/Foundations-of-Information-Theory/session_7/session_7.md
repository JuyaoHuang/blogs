---
title: 有噪信道编码
published: 2026-01-08
description: "信息量基础：有噪信道编码"
first_level_category: "知识库"
second_level_category: "信息论"
tags: ['信息论']
draft: false
---

![1](./1.jpg)

## 1. 概述

信道编码就是按一定的规则给信源输出序列增加某些冗余符号，使其变成满足一定数学规律的码序列(或码字)，再经信道进行传输。

信道译码就是按与编码器同样的数学规律去掉接收序列中的冗余符号，恢复信源消息序列。

一般地说，所加的冗余符号越多，纠错能力就越强，但传输效率降低。因此在信道编码中明显体现了传输有效性与可靠性的矛盾。长期以来人们总是认为编码的高可靠性一定伴随低的传输有效性。而在香农提出**有噪信道编码定理**以前，就有人指出这是一种不正确的传统观念。

因为本章研究的是通信系统中的信道与信道编、译码器，所以我们把信源和信源编码器合并在一起看成信源，信源译码器和信宿合并在一起看成信宿。

这样，简化的通信系统模型如图：

![2](./2.jpg)

![2](./3.jpg)
![2](./4.jpg)

用通信原理的 MDPSK 调制类比：

1. 输入端是一个随机序列 $\{a_n\}$，有 $M$ 个取值。
2. 编码器阶段就是将该序列进行 PAM 调制，成为脉冲序列，然后对其进行差分编码（使用码字进行代替），得到编码序列 $\{b_n\}$。
3. 然后通过信道进行传输：信道根据 $\{b_n\}$的维度进行扩展，以适配传输。也就是信道的带宽要能够使信号无损经过信道。信道的传递函数，即输出端 $Y$ 与输入端 $X$ 的关系可用转移概率矩阵进行描述。
4. 接收到含有噪声的信号 $Y(t)$ 后进行相干解调和码反变换（译码），得到恢复的消息序列 $\{a^`_n\}$

![5](./5.jpg)

### 信息传输速率

**也就是传码率$R_b$**。其中 $M$ 为码字的个数，$n$ 为码长。

![6](./6.jpg)

## 2. 判决

*此部分太过抽象，使用通信原理的概念更好理解。*

![2](./2.jpg)

![7](./7.jpg)
![7](./8.jpg)

> **文中的 $a_j$ 是误印**

$$
g(y=b_j) = a^*
$$
是指当接收到 $b_j$ 是就认为发送端 $X$ 发的是符号 $a^*$。

> 注意：接收端 $Y$ 并不知道发送端发的是什么，它只是根据预先设置的规则，也叫判决域，对接收到的内容进行判别。

所以**判决规则**就是：当接收到 $b_j$ 时，输入端正好发的也是 $a^*$。如果输入端发的是其他符号，但接收端认为其发的符号是 $a^*$，此时产生了**错误比特**。

**错误率公式解读**：
$$ 
p(e|x=a_i) = \sum_{y, g(y) \neq a_i} p(y|x=a_i) 
$$
这个公式的意思就是在表示该判决规则：输出端的判决出现失误：输入端发的是 $a_i$，但此时接收端接收到的是其他输入符号 $a_k$ 对应的码元符号 $b_k$，不是 $a_i$ 对应的符号 $b_i$。因此接收端判决时判决为其他的码元符号 $a_k,\ k \neq i$。**由此出现了错误率**

> **文中的 $a_j$ 是误印**

- $x=a_i$：此时输入端实际发的是 $a_i$
- $g(y) \neq a_i$：接收端没有判为 $a_i$ 对应的符号 $b_i$，而是判断为其他符号 $a_k$ 对应的 $b_k$ 符号，产生了误判
- $p(y|x=a_i)$：求这种误判发生的概率。即在发 $a_i$ 的情况下，刚好收到这个错误符号 $y = b_k$ 的概率
  
即：在发送端发送 $a_i$ 的前提下，接收端接收到了某个符号 $y$（比如 $b_j$），而这个 $y$ 经过翻译（判决）后，被指认成了别的对象（不是 $a_i$），从而导致了“张冠李戴”的概率总和。

> **注意**：
> - 发送端发的是 $a_i$
> - 信道接收端收的是 $b_i$
> - 最后是根据 $b_i$ 进行判决，判断输入端发的是 $a_i$ 还是其他符号 

---

**使用通信原理来理解**：

**1. 假设**
假设我们是一个最简单的二进制系统 BPSK：

- 发送端 ($x$)有两个符号 $a_1$ 和 $a_2$
  - 发送 $a_1$ (逻辑 0) $\rightarrow$ 发送电压 $-A$ 伏特
  -  发送 $a_2$ (逻辑 1) $\rightarrow$ 发送电压 $+A$ 伏特
- 信道：叠加 AWGN
- 接收端 ($y$)：收到的是连续电压值 $y(t)$

**2. 判决规则 $g(y)$**

在《通信原理》中，判决器是一个比较器。

![9](./9.jpg)

对于上述双极性信号，最佳判决门限是 $0$ 伏特。

判决规则 $g(y)$ 定义如下：
*   如果收到电压 $y < 0$ $\rightarrow$ 判决为 $a_1$ (逻辑 0)
*   收到电压 $y > 0$ $\rightarrow$ 判决为 $a_2$ (逻辑 1)

再看此错误率（这里叫误码率）公式：
$$ 
p(e|x=a_i) = \sum_{y, g(y) \neq a_i} p(y|x=a_i) 
$$
假设此时发送的是 $a_1$。

在这个假设下：我们希望接收到的电压 $y$ 应该在 $-A$ 附近，保持在 $0$ 以下（$y < 0$）。此时 $g(y) = a_1$，判决正确。
而**错误的情况**就是信道的早上干扰太大，将电压抬高到了门限 0 以上，导致此时比较器（判决器）判决为 $g(y) = a_2$，即公式条件里的$g(y) \neq a_1$，导致**误判**。

公式含义即：
$$ 
p(e|x=a_1) = \underbrace{\sum_{y, g(y) \neq a_1}}_{\text{积分范围：跨过门限的区域}} \underbrace{p(y|x=a_1)}_{\text{噪声的概率密度}} 
$$

---

这是对单个输入符号码字（我习惯通信原理，称其为码元）的情况，由此可以定义出**平均错误率**：

![10](./10.jpg)

人话就是计算每个输入码元的误比特率，然后再乘上输入端发送该码元的概率。

**平均正确率**显然为平均错误率的差：

![10](./11.jpg)

**示例**：

![12](./12.jpg)

## 3. 译码规则

译码规则主要有两种：
- MAP 准则，最大后验概率准则
- ML 准则，最大似然概率准则

### 3.1. 贝叶斯公式 ---- 两个译码规则的祖宗

在通信系统中，通常用 $x$ 表示发送端的输入符号，用 $y$ 表示接收端的输出符号。

贝叶斯公式描述了**条件概率**之间的转换关系：
$$ 
p(x|y) = \frac{p(y|x) p(x)}{p(y)} 
$$
- $p(x)$：**先验概率**。即在没有收到任何信号之前，发送端发送符号 $x$ 的概率（由信源的统计特性决定）
- $p(y|x)$：**似然概率** 或转移概率。这是信道的特性，表示如果发送了 $x$，信道输出 $y$ 的概率
- $p(y)$：归一化常数。表示收到符号 $y$ 的总概率，即 $y = b_i$ 的边缘概率
  $$ 
  p(y) = \sum_{x} p(x) p(y|x) 
  $$
- $p(x|y)$：**后验概率**。即“在已经收到 $y$ 的条件下，推断发送端发送的是 $x$ 的概率”

### 3.2. MAP 准则

MAP 准则的核心思想：

当接收端收到符号 $y$ 后，它会猜测：“哪个发送符号 $x$ 最有可能导致我收到这个 $y$ ？”显然，应该选择那个让 **后验概率 $p(x|y)$ 最大** 的 $x$ 作为判决结果。

假设判决结果为 $a^*$（即猜测发送的是 $a^*$），那么 MAP 准则要求 $a^*$ 满足：
$$ 
a^* = \arg \max_{a_i} p(x=a_i | y)
$$
利用上面的贝叶斯公式代入：
$$ 
a^* = \arg \max_{a_i} \frac{p(y | x=a_i) p(x=a_i)}{p(y)} 
$$
> 注意分母 $p(y)$ 对于所有的假设 $a_i$ 都是一样的
> 
> 因为 $y$ 已经被接收下来了，是一个既定事实，常数。因此，在比较大小时，可以忽略分母。

于是，MAP 判决准则简化为：

$$ 
a^* = \arg \max_{a_i} \underbrace{p(y | x=a_i)}_{\text{信道特性}} \cdot \underbrace{p(x=a_i)}_{\text{信源统计特性}} 
$$

即：译码器寻找的是“信道转移概率”与“信源先验概率”乘积最大的那个输入符号。

**似然比形式**
$$ 
\Lambda = \frac{p(y | x=a^*)}{p(y | x=a_i)} \ge \frac{p(x=a_i)}{p(x=a^*)} 
$$

这是 MAP 准则的另一种变形，常用于二元假设检验或两两比较。

如果比较两个可能的发送符号 $a^*$ 和 $a_i$。根据 MAP 准则，若要判定是 $a^*$ 而不是 $a_i$，则必须满足：
$$
p(x=a^* | y) \ge p(x=a_i | y) 
$$
代入贝叶斯公式并消去分母 $p(y)$：

$$ 
p(y | x=a^*) p(x=a^*) \ge p(y | x=a_i) p(x=a_i) 
$$

将含有 $y$ 的项移到左边，含有 $x$ 先验概率的项移到右边，就得到了图片中的**似然比** 形式：

$$ 
\Lambda = \frac{p(y | x=a^*)}{p(y | x=a_i)} \ge \frac{p(x=a_i)}{p(x=a^*)} 
$$
- 左边 $\Lambda$：似然比，仅与信道特性和接收到的 $y$ 有关
- 右边：判决门限，仅与信源的先验概率有关


#### **如何应用**：

由前文的**似然比**形式就可知道，将此形式转为以下形式：
$$ 
p(y | x=a^*) p(x=a^*) \ge p(y | x=a_i) p(x=a_i) 
$$
即 $a^*$ 与 $y$ 的联合概率，$a_i$ 与 $y$ 的联合概率，这两个输入符号联合概率的比较。
> 注意此时 $y$ 是一个**常数**，例如 $y = y_i$

该公式就是在不同的输入符号里选择一个**有最大的联合概率的符号值**。

**所以核心就是**：
1. 求出输入端符号 $X = a_i$ 和输出端符号 $Y= b_j$ 的联合概率分布
2. 在联合概率分布里寻找**每一列最大的概率值对应的输入符号**
3. 该输入符号就是最佳判决门限：$g(y)=a^*$

#### **示例**：

假设联合概率分布第一列标签（输出端符号）为 $b_1$，然后输入端第二个符号 $a_2$ 的联合概率最大（此时输出符号固定，为 $b_1$）。

那么当接收端输入为 $b_1$ 时，它的最佳判别门限就是 $a_2$。即：
$$
g(y = b_1) = a_2
$$
$a^2$就是期望的 $a^*$。

**示例一**：

![14](./13.jpg)

![14](./14.jpg)

即当 $y=b_1$时（y 固定），求解发现当输入符号是 $a_1$ 时，联合概率最大，因此最佳判决门限（判决结果）为 $a_1$。

**示例二**：

![15](./15.jpg)

**所以求解 MAP 准则的核心就是：求解联合概率矩阵**。

### 3.3. ML 准则

相较于 MAP，ML并不考虑先验概率，只考虑似然概率的最大值。即：在当前接收的码元（输出端符号）为 $b_i$ 的情况下，此时发送端发送的符号 $a_i$ 的最大概率。**也就是似然概率最大的输入码元**。而**似然概率就是信道的转移概率矩阵！**

**所以求解方法：**
1. 直接看信道的转移概率矩阵的每一列
2. 找到条件概率最大的那一个输入符号
3. 这个符号就最佳判决门限

![16](./16.jpg)

#### 示例：

**示例一**

假设一个二进制对称信道，输入符号集 $A=\{0, 1\}$，输出符号集 $B=\{0, 1\}$。信道的误码率为 $p$ (假设 $p < 0.5$)。

**信道转移概率矩阵 $P(Y|X)$ 如下：**

$$
\begin{array}{c|cc}
P(y|x) & y=0 & y=1 \\
\hline
x=0 & 1-p & p \\
x=1 & p & 1-p
\end{array}
$$

**求解判决函数 $g(y)$ 的步骤：**

1.  当接收到 $y=0$ 时：
    *   比较 $x=0$ 发送 $y=0$ 的概率：$p(y=0|x=0) = 1-p$
    *   比较 $x=1$ 发送 $y=0$ 的概率：$p(y=0|x=1) = p$
    *   因为题目假设 $p < 0.5$，所以 $1-p > p$。
    *   结论：最大值对应 $x=0$，所以 $g(0) = 0$。

2.  当接收到 $y=1$ 时：
    *   比较 $x=0$ 发送 $y=1$ 的概率：$p(y=1|x=0) = p$
    *   比较 $x=1$ 发送 $y=1$ 的概率：$p(y=1|x=1) = 1-p$
    *   因为 $1-p > p$。
    *   结论：最大值对应 $x=1$，所以 $g(1) = 1$。

**最终判决规则**：
$$ 
g(y) = y 
$$
即：收到什么就认为是发了什么（前提是误码率 $p < 0.5$）。

#### **总结**

在先验概率未知的情况下使用 ML 准则，只需要拿着接收到的 $y$，去信道矩阵里找**那一列中最大的数值**，它对应的行标（输入符号）就是最佳判决结果

### ML准则示例

#### 1. 确定最佳判决准则

在题目第（2）问中，明确指出“不知道妈妈、奶奶和爸爸准备晚餐的概率”。

这意味着无法获知信源的先验概率 $p(x)$。

根据信息论基础，当先验概率未知（或假设等概）时，为了使错误率尽可能小，应采用最大似然准则。

**结论**：最佳判决准则是最大似然准则 (ML)。

---

#### 2. 求判决函数

首先，将题目给出的条件整理为信道转移概率矩阵 $P(Y|X)$。

设输入符号空间 $X = \{x_1(\text{妈妈}), x_2(\text{奶奶}), x_3(\text{爸爸})\}$

设输出符号空间 $Y = \{y_1(\text{米饭}), y_2(\text{面条}), y_3(\text{饺子})\}$

矩阵中元素为 $p(y_j | x_i)$：

$$
\mathbf{P} = \begin{bmatrix}
0.5 & 0.3 & 0.2 \\
0.2 & 0.3 & 0.5 \\
0.2 & 0.4 & 0.4
\end{bmatrix}
\begin{matrix}
\leftarrow x_1 (\text{妈妈}) \\
\leftarrow x_2 (\text{奶奶}) \\
\leftarrow x_3 (\text{爸爸})
\end{matrix}
$$
$$
\begin{matrix}
\uparrow & \uparrow & \uparrow \\
y_1 & y_2 & y_3
\end{matrix}
$$

**应用最大似然准则**：对于每一个接收到的 $y_j$，在对应的**列**中寻找最大的概率值，其对应的 $x_i$ 即为判决结果。

1.  当收到 $y_1$ (米饭) 时：
    *   比较第一列的数值：$p(y_1|x_1)=0.5, \quad p(y_1|x_2)=0.2, \quad p(y_1|x_3)=0.2$
    *   最大值为 $0.5$，对应 $x_1$ (妈妈)
    *   判决：$g(y_1) = x_1$ (妈妈)

2.  当收到 $y_2$ (面条) 时：
    *   比较第二列的数值：$p(y_2|x_1)=0.3, \quad p(y_2|x_2)=0.3, \quad p(y_2|x_3)=0.4$。
    *   最大值为 $0.4$，对应 $x_3$ (爸爸)
    *   判决：$g(y_2) = x_3$ (爸爸)

3.  当收到 $y_3$ (饺子) 时：
    *   比较第三列的数值：$p(y_3|x_1)=0.2, \quad p(y_3|x_2)=0.5, \quad p(y_3|x_3)=0.4$。
    *   最大值为 $0.5$，对应 $x_2$ (奶奶)
    *   判决：$g(y_3) = x_2$ (奶奶)

**综上，判决函数为：**
$$
g(y) = \begin{cases}
\text{妈妈}, & \text{若晚餐是米饭 } (y=y_1) \\
\text{爸爸}, & \text{若晚餐是面条 } (y=y_2) \\
\text{奶奶}, & \text{若晚餐是饺子 } (y=y_3)
\end{cases}
$$

---

#### 3. 求对应的平均错误率

**注意**：虽然在制定判决规则时假装不知道先验概率（使用了 ML 准则），但在计算实际平均错误率时，必须使用客观存在的真实先验概率（即题目最开始给出的数据），因为这是系统真实的物理属性。

**真实先验概率：**

$$ 
p(x_1) = 1/2 = 0.5, \quad p(x_2) = 1/4 = 0.25, \quad p(x_3) = 1/4 = 0.25 
$$

**计算平均正确率 $P_c$：**

平均正确率等于所有“正确判决情况”的联合概率之和。根据判决函数 $g(y)$，正确组合是：
1.  发送 $x_1$ (妈妈) 且收到 $y_1$ (米饭)
2.  发送 $x_3$ (爸爸) 且收到 $y_2$ (面条)
3.  发送 $x_2$ (奶奶) 且收到 $y_3$ (饺子)

$$
\begin{aligned}
P_c &= p(x_1)p(y_1|x_1) + p(x_3)p(y_2|x_3) + p(x_2)p(y_3|x_2) \\
&= (0.5 \times 0.5) + (0.25 \times 0.4) + (0.25 \times 0.5) \\
&= 0.25 + 0.10 + 0.125 \\
&= 0.475
\end{aligned}
$$

**计算平均错误率 $P_e$：**
$$
P_e = 1 - P_c = 1 - 0.475 = 0.525
$$